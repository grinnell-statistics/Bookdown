<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 The Design and Analysis of Factorial Experiments: Microwave Popcorn | A Book Chapter Example</title>
<meta name="author" content="Your Name">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 4 The Design and Analysis of Factorial Experiments: Microwave Popcorn | A Book Chapter Example">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 The Design and Analysis of Factorial Experiments: Microwave Popcorn | A Book Chapter Example">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="However beautiful the strategy, you should occasionally look at the results. - Winston Churchill Statistics ought to be viewed as a whole: understanding the process of formulating questions,...">
<meta property="og:description" content="However beautiful the strategy, you should occasionally look at the results. - Winston Churchill Statistics ought to be viewed as a whole: understanding the process of formulating questions,...">
<meta name="twitter:description" content="However beautiful the strategy, you should occasionally look at the results. - Winston Churchill Statistics ought to be viewed as a whole: understanding the process of formulating questions,...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Book Chapter Example</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled"><li><a class="" href="index.html"><span class="header-section-number">Chapter 4</span> The Design and Analysis of Factorial Experiments: Microwave Popcorn</a></li></ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/rstudio/bookdown-demo">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="the-design-and-analysis-of-factorial-experiments-microwave-popcorn" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> The Design and Analysis of Factorial Experiments: Microwave Popcorn<a class="anchor" aria-label="anchor" href="#the-design-and-analysis-of-factorial-experiments-microwave-popcorn"><i class="fas fa-link"></i></a>
</h1>
<p><span style="float:right;"> <em>However beautiful the strategy, you should occasionally look at the results.</em> </span><br><span style="float:right;"> - Winston Churchill</span></p>
<p><br><br></p>
<p>Statistics ought to be viewed as a whole: understanding the process of formulating <em>questions</em>, properly designing a study, actively collecting meaningful data, and then deciding how to properly organize and draw conclusions from the data. Advancements in technology have made data collection and computationally intensive statistical techniques much more feasible. At one time, many statisticians had narrowly defined roles and were considered as primarily “number crunchers.” Today, statisticians characteristically work on interdisciplinary teams that emphasize scientific inference and understanding data in context.</p>
<p>Instead of emphasizing formulas, computation, and mathematical theory, this chapter uses a simple popcorn experiment to demonstrate the numerous challenges that can occur in designing experiments and collecting data.</p>
<p>In this chapter, you will have the opportunity to:</p>
<ul>
<li>Key features of a well‑designed experiment and proper data collection<br>
</li>
<li>Proper determination of response variables, experimental factors, and levels<br>
</li>
<li>Building on the one‑way ANOVA discussed in Chapter 2 to describe multivariate factorial designs<br>
</li>
<li>Evaluating multiple hypotheses based on main effects and interaction terms<br>
</li>
<li>Calculating each of the between‑group and within‑group variances needed in ANOVA tables for balanced factorial designs<br>
</li>
<li>Calculating effects and developing mathematical models<br>
</li>
<li>Using multiple comparison tests with ANOVA tables</li>
</ul>
<div id="investigation-which-microwave-popcorn-is-the-best" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> <strong>Investigation: Which Microwave Popcorn Is the Best?</strong><a class="anchor" aria-label="anchor" href="#investigation-which-microwave-popcorn-is-the-best"><i class="fas fa-link"></i></a>
</h2>
<p>Popcorn is a staple for many college students. While many students like popcorn because it is inexpensive and easy to prepare, it is also a whole grain food that’s low in fat and calories. According to The Popcorn Institute, Americans consume an average of 54 quarts of popcorn a year per person.</p>
<p>Two popcorn lovers, who also happened to be taking a statistics course, decided to test whether there is a difference in quality between microwave popcorn brands. Yvonne and Tue wanted to know if a cheaper brand of popcorn was just as good as more expensive popcorn. These students could have chosen to conduct a study that could be analyzed with a two‑sample <em>t</em>‑test if they had simply compared two brands of popcorn. However, if they did a two‑sample <em>t</em>‑test, they would need to hold many factors constant, such as the type of microwave, cooking time, and storage procedures. Since Yvonne and Tue believed that some of these factors could also impact the quality of the popcorn, they decided to include some of these additional factors in their study.</p>
<p>Modeling real‑world phenomena often requires more than just one factor to explain changes in the response. <strong>Factorial designs</strong> are any statistical designs that are structured to use factors (i.e., explanatory variables) to organize meaningful groups of treatment conditions. A two‑sample <em>t</em>‑test can be considered a special case of a factorial design that has just one factor (popcorn brand in this case) and two levels (Brand A and Brand B). Factorial designs are very powerful statistical tools because they allow a researcher to simultaneously test the effects of multiple factor‑level combinations on a response of interest.</p>
<p><br>
In factorial designs, each explanatory variable is called a <strong>factor</strong> and specific conditions within each factor are called <strong>levels</strong>. In any study, these factor‑level combinations are called <strong>conditions</strong>; in experiments, they are often called <strong>treatments</strong>. Factorial designs are often used to test the effects of multiple factors simultaneously, where each factor has two or more levels.<br></p>
</div>
<div id="elements-of-a-well-designed-experiment" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> <strong>Elements of a Well-Designed Experiment</strong><a class="anchor" aria-label="anchor" href="#elements-of-a-well-designed-experiment"><i class="fas fa-link"></i></a>
</h2>
<p>Unfortunately, many people mistakenly believe that statistics is only a process of performing mathematical calculations on data in order to examine the validity of a hypothesis. Proper experimental design is just as important as, if not more important than, the choice of statistical calculations. In fact, designing experiments and collecting appropriate data are often the most difficult and time-consuming aspects of conducting experiments.</p>
<p><br>
A good design attempts to answer the question(s) of interest as clearly and efficiently as possible. Any statistical analysis is only as good as the quality of the data.<br></p>
<p>An <strong>experiment</strong> is defined as a study in which purposeful changes are made to controlled conditions in order to identify changes in a response. An experiment imposes a treatment on subjects or experimental units, while an <strong>observational study</strong> simply collects data under varying conditions without imposing any changes. Well-designed experiments are conducted under controlled conditions to make it easier to isolate the impact of each treatment combination. In observational studies, the conditions in the study are rarely the only characteristic that makes the two (or more) populations different. Thus, unknown factors that may bias the results are unfortunately built into an observational study.</p>
<p><br>
Both experiments and observational studies use sample data to draw conclusions about a larger population, process, or system. It is often much easier to show cause and effect relationships in a well-designed experiment because conditions are controlled.<br></p>
<p><br>
Some texts state that only experiments can be used to show cause and effect relationships. However, poorly designed experiments should not be used to show causation. In addition, observational studies (such as those testing a relationship between smoking and lung cancer) can be used to show causation if (1) there is a strong association between the explanatory and response variables, (2) higher doses are associated with stronger responses (e.g., more cigarettes increase the likelihood of getting cancer), (3) there are consistent results across many studies, and (4) there are credible explanations for the cause and effect relationship.<br></p>
<p><strong>Experimental design</strong> is the process of planning an experiment that collects the right amount and type of data to answer a question of interest. Several decisions need to be made about how an experiment is to be constructed and executed to ensure that the experimental results are valid. Taking the time to properly design an experiment will improve the precision of answers to research questions. In addition, well-designed experiments often are much more efficient and obtain stronger conclusions than other studies.</p>
<p>The first step in designing an experiment is to clearly define a problem and state the objectives of the experiment. This is often much more difficult than it first appears. Before any data are collected, it is essential that everyone involved understand the objectives of the experiment, what measurements will be taken, what material is needed, and what procedures will be used. Good experimental design typically involves gaining background knowledge outside the field of statistics.</p>
<p>There are many possible ways to conduct an experiment to determine the effect of brand on the quality of popcorn. While microwave popcorn is something these students were quite familiar with, they needed to determine which brands to compare, the appropriate cooking time (which could vary by microwave), and how to define and measure “good” popcorn.</p>
</div>
<div id="identifying-a-response-variable" class="section level2 unnumbered">
<h2>Identifying a Response Variable<a class="anchor" aria-label="anchor" href="#identifying-a-response-variable"><i class="fas fa-link"></i></a>
</h2>
<p>Many possible measurements could be taken on microwave popcorn. Yvonne and Tue could have created a taste rating or a texture rating, measured the volume of the kernels, counted the number of popped kernels, or calculated the percentage of “old maids,” the kernels that did not pop after the bag had been cooked.</p>
<p>Identifying the response variable corresponds to determining what measurements should be taken. Each experiment should ensure that the response variable provides the information needed and that the response measurement is precise enough to address the question of interest. Yvonne and Tue determined that their definition of “quality” popcorn would be popcorn that had the highest percentage of popped kernels per bag. Notice that if Yvonne and Tue had counted only the popped kernels, and not the unpopped kernels, they might have gotten a distorted response, since some brands may tend to have more kernels per bag.</p>
<p>Yvonne and Tue initially discussed randomly sampling 20 kernels from each popped bag and calculating the percentage of popped kernels. However, the size and shape differences between popped and un-popped kernels would have made it rather difficult to simply pull out a random sample. Thus, in order to ensure their counts were as accurate as possible, they decided to count every kernel in every bag of their experiment.</p>
<p>It is also useful to discuss the range and variability of responses expected to be observed. For example, if we conducted a study under conditions that typically gave only two outcomes, either 0% or 100%, the response would be categorical (such as yes/no or popped/not popped), and then an analysis based on categorical response variables should be used. Studies with categorical response variables can be analyzed with techniques such as the chi-square test or logistic regression, which are discussed in Chapters 6 and 7, respectively.</p>
<p>The percentage of popped kernels was considered a quantitative response variable in this experiment. Background research showed that some popcorn companies expected between 94% and 97% popped kernels, but based on their prior popcorn eating experience, Yvonne and Tue expected the percentage to be a little lower. In Yvonne and Tue’s study, they roughly estimated that responses should be between 60% and 99% popped kernels, with an average close to 90%.</p>
<p><br>
Care needs to be taken before a study is conducted to ensure that the response measurement is accurate and applicable to the research question.<br></p>
</div>
<div id="identifying-the-factors-and-levels" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> <strong>Identifying the Factors and Levels</strong><a class="anchor" aria-label="anchor" href="#identifying-the-factors-and-levels"><i class="fas fa-link"></i></a>
</h2>
<p>The next step in designing an experiment is to investigate any factors that may be of importance or may potentially bias the results. Yvonne and Tue had two microwaves that they typically used to make popcorn, one in their dorm lounge and one in their room. The lounge microwave had a “popcorn” setting, which cooked for 1 minute 45 seconds, though the package instructions for each brand suggested varying cooking times. Most microwaves also have power settings. Should popcorn always be popped at the highest power setting?</p>
<p>With a little research, these students found that the quality of popcorn can also be affected by how it is stored. Popcorn stored in a moisture-rich environment, such as a refrigerator, tends to have a higher percentage of popped kernels. However, too much moisture may cause the popcorn to have a gummy texture. Finally, Yvonne and Tue wanted to compare a relatively expensive brand of popcorn (Pop Secret) to a relatively inexpensive brand (Fastco). Each of these brands also has a variety of flavors, such as butter, kettle corn, and caramel.</p>
<p>Notice that the discussion of factors and potential levels is based not on statistical calculations, but on nonstatistical knowledge. Nonstatistical knowledge is often essential in choosing factors, determining factor levels, and interpreting the results of a study.</p>
<p>Yvonne and Tue decided on three factors of interest, factors that would be included in the study to determine if different levels impact the results:</p>
<p>Factor 1: popcorn Brand at two levels, Fastco and Pop Secret<br>
Factor 2: Microwave at two levels, Lounge and Room<br>
Factor 3: cooking Time at two levels, 105 seconds and 135 seconds</p>
<p>It can sometimes be difficult to identify a reasonable range for each factor. Yvonne and Tue had noticed that some brands of popcorn tended to burn at around 150 seconds (2.5 minutes). Even though cooking popcorn longer than 135 seconds might increase the percentage of popped kernels, Yvonne and Tue decided to avoid cooking times likely to cause burning.</p>
<p>Yvonne and Tue then listed suspected extraneous variables, other factors that need to be controlled during the experiment to eliminate potential biases. Yvonne and Tue decided to hold some extraneous variables constant. In particular, they used only the highest power setting on each microwave, they stored all the popcorn on a shelf in their room, and they used only the butter flavor of each brand. There were other variables they could not control, such as age of the popcorn, which manufacturing plant prepared each bag of popcorn, and how different retail stores had stored the popcorn. To account for the extraneous variables they could not control (or had not even thought of), it would be best to randomly select bags of popcorn from the entire population. Instead, Yvonne and Tue did their best to randomly select several bags of Fastco and Pop Secret butter popcorn from a variety of stores in town. This was not a true random sample, and Yvonne and Tue had to be careful in making any statements about how the results of their study extended to a larger population. In addition, when possible, each bag of popcorn in the study was randomly allocated to a factor-level combination. While bags of popcorn can be randomly assigned to a cooking time and microwave, they cannot be randomly assigned to a popcorn brand.</p>
<p><br>
A good design controls for known extraneous variables (often by holding them constant throughout
the study) and then uses random sampling and random allocation to control for any other unknown or
uncontrollable extraneous variables.
</p>
</div>
<div id="choosing-a-design" class="section level2 unnumbered">
<h2>Choosing a Design<a class="anchor" aria-label="anchor" href="#choosing-a-design"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to determining what conditions to test and what measurements to take, in order to create a good experimental design, a researcher must properly define units and determine how units are structured. An <strong>experimental unit</strong> is the smallest part of experimental material that is assigned (randomly, if possible) to a factor-level combination within a study. Since Yvonne and Tue counted every kernel of popcorn, some may incorrectly assume that each kernel is a unit. In an experiment, units are randomly assigned to treatments. In this study, each kernel was not randomly assigned to a condition, but each bag of popcorn was randomly assigned to be popped in a particular microwave for a particular length of time. Thus, bags of popcorn are considered the units for Yvonne and Tue’s study.</p>
<p><br>
If (1) units are as similar as possible, (2) units are randomly assigned to treatment combinations, and (3) large enough sample sizes are used, then we can conclude that statistically significant differences in the response can be explained by the different treatment combinations.
</p>
<p>This chapter will focus on <strong>completely randomized factorial designs</strong>. In completely randomized designs, each unit is assigned to exactly one factor-level combination. Only one measurement is collected for each unit. In the following section, we will use Yvonne and Tue’s data to simultaneously test for the effects of two brands, two cooking times, and two microwaves on the percentage of popped kernels.</p>
<p><br>
While this chapter focuses only on completely randomized factorial designs, it is important to recognize the difference between completely randomized, <strong>block and split-plot</strong> or (<strong>repeated measures</strong>) designs. If each unit is assigned to only one factor-level combination, it is appropriate to use a completely randomized design. If each unit is assigned to several conditions or multiple measurements are taken on each unit, a more complex design structure, such as a block or split-plot (repeated measures) design, may be needed.</p>
<p>Block and split-plot (repeated measures) designs also work with different types of factors. The factors of interest in this chapter all have fixed effects. <strong>Fixed effects</strong> correspond to factors where each level is selected because it is of specific interest to the researcher. <strong>Random effects</strong> correspond to factors where the levels are randomly selected from a larger population. All factors in a completely randomized design are also <strong>crossed</strong>; this means that every level of each factor can be tested in combination with every level of every other factor. Alternatively, <strong>nested factors</strong> are factors for which some levels cannot occur simultaneously with other factor levels. Random effects and nested factors can be analyzed with block and split-plot (repeated measures) designs; they are described in Chapter 5.
</p>
<p><br>
If possible, a straightforward design and analysis are usually better than a complex design and analysis. If the design is too complicated and the data are not collected properly, even the most advanced statistical techniques may not be able to draw appropriate conclusions from an experiment.
</p>
</div>
<div id="determining-sample-sizes-for-completely-randomized-designs" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> <strong>Determining Sample Sizes for Completely Randomized Designs</strong><a class="anchor" aria-label="anchor" href="#determining-sample-sizes-for-completely-randomized-designs"><i class="fas fa-link"></i></a>
</h2>
<p>When more units are tested, it is more likely that the statistical analysis will identify true differences between conditions. However, every unit tested has a cost, and it is important to carefully determine how many units are practical to test. Is it worth testing additional units to gain a better understanding of the unit-to-unit variability?</p>
<p>Yvonne and Tue estimated that they could each count the kernels in one bag (popped and unpopped) in 10 to 15 minutes. They also thought that they could get a few close friends to count a few bags in exchange for free popcorn. Care should always be taken when measuring results. If the result is a subjective measurement (such as the taste of popcorn or the quality of artwork), very clear procedures should be written and, if possible, the same people should record each measurement. In this popcorn study, counting the percentage of popped kernels per bag is an objective measurement. As long as Yvonne and Tue have trustworthy friends, there should be no problem in having several people help count popcorn kernels.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Ideally, they would have preferred to have at least two people count each bag to ensure against errors, but that would have doubled the time needed to conduct the experiment. Repeatability and reliability (often called gauge R&amp;amp;R) studies are a technique discussed in many quality control texts as a way to ensure that different people or processes provide similar results.
&lt;/p&gt;"><sup>1</sup></a> They estimated that they could conduct 32 tests in about four hours.</p>
<p>The choice of 32 tests, instead of a round number like 30, is also related to a well-designed experiment. Yvonne and Tue found that, based on their choice of factors and levels, there were a total of eight treatment combinations. Table 4.1 lists the eight possible treatment conditions that can be “assigned” to each bag of popcorn. Yvonne and Tue wanted to have a balanced design, a design where the same number of units is assigned to (or randomly selected from) each condition. Balanced designs are often easier to analyze and more likely to identify true differences in the effects of different conditions.<span class="math inline">\(^3\)</span> If Yvonne and Tue wanted to conduct a balanced design, they needed to conduct tests in a multiple of 8 (16, 24, etc.).</p>
<p><br>
Table 4.1 lists the variables in standard order. Listing conditions in <strong>standard order</strong> is a simple technique that ensures that each factor combination is listed exactly once. The first variable alternates levels every row. For the second variable, levels alternate every other row. The third variable alternates every fourth row. This same process can work for multiple factors with multiple levels. If there were four factors, each with two levels, the fourth column would alternate every eight rows. For studies with more than two levels, simply ensure that the current variable lists each level exactly once for all prior combinations.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Activity: Determining the Number of Treatment Combinations {‑}
&gt;1. Assume we want to use three cooking times for popping the popcorn instead of two. List the possible treatment combinations that can be assigned. How many are there?
2. Without listing all possibilities, calculate how many treatment combinations would exist for a design that tested five brands with three microwaves at four cooking times.</p>
</div>
<div id="analyzing-a-two-way-factorial-design" class="section level2" number="4.5">
<h2>
<span class="header-section-number">4.5</span> <strong>Analyzing a Two-Way Factorial Design</strong><a class="anchor" aria-label="anchor" href="#analyzing-a-two-way-factorial-design"><i class="fas fa-link"></i></a>
</h2>
<p>Since several factors are included in this experiment, there are also several hypotheses to be tested. Yvonne and Tue actually had six research questions, which will be discussed in Section 4.4. But to keep the calculations simple, in this section we will assume that only two factors were tested (<em>Brand</em> and <em>Time</em>). This leads to three hypotheses corresponding to the <em>Brand</em> and <em>Time</em> factors.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(H_{0,1}: \mu_{\text{Fastco}} = \mu_{\text{PopSecret}}\)</span>; there is no difference in the mean response (<em>PopRate</em>) between the two <em>Brands</em>.<span class="math inline">\(^*\)</span><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(^*\)&lt;/span&gt;This is often written as &lt;span class="math inline"&gt;\(H_{0,1}\)&lt;/span&gt;: there is no &lt;em&gt;Brand&lt;/em&gt; effect or &lt;span class="math inline"&gt;\(H_{0,1}: \alpha_{\text{Fastco}} = \alpha_{\text{PopSecret}} = 0\)&lt;/span&gt;, where &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt; is called the effect size. For example, &lt;span class="math inline"&gt;\(\alpha_{\text{Fastco}} = \mu_{\text{Fastco}} - \mu\)&lt;/span&gt;, where &lt;span class="math inline"&gt;\(\mu\)&lt;/span&gt; is the overall grand mean of the responses.&lt;/p&gt;'><sup>2</sup></a><br><span class="math inline">\(H_{a,1}: \mu_{\text{Fastco}} \ne \mu_{\text{PopSecret}}\)</span>; the two <em>Brand</em> means are different.</p></li>
<li><p><span class="math inline">\(H_{0,2}: \mu_{105} = \mu_{135}\)</span>; there is no difference in the mean <em>PopRate</em> for the two <em>Times</em>.<br><span class="math inline">\(H_{a,2}: \mu_{105} \ne \mu_{135}\)</span>; the two <em>Time</em> means are different.</p></li>
<li><p><span class="math inline">\(H_{0,3}\)</span>: <em>Brand</em> has no influence on how <em>Time</em> affects <em>PopRate</em>. This is equivalent to stating <span class="math inline">\(H_{0,3}\)</span>: <em>Time</em> has no influence on how <em>Brand</em> affects <em>PopRate</em> or <span class="math inline">\(H_{0,3}\)</span>: the effect of <em>Time</em> is the same for both <em>Brands</em> or <span class="math inline">\(H_{0,3}\)</span>: there is no interaction between <em>Time</em> and <em>Brand</em>.<br><span class="math inline">\(H_{a,3}\)</span>: <em>Brand</em> influences how <em>Time</em> affects <em>PopRate</em> or <span class="math inline">\(H_{a,3}\)</span>: there is an interaction between <em>Time</em> and <em>Brand</em>.</p></li>
</ol>
<p>Factorial designs are efficient because much more information can be calculated, such as <span class="math inline">\(p\)</span>-values for multiple hypothesis tests, without requiring more experimental units than for the typical two-sample <span class="math inline">\(t\)</span>-test. Factorial designs are very beneficial in situations where experimental units are expensive or difficult to obtain. The next sections will discuss how to organize and draw conclusions for each of the above hypotheses in a factorial design with two factors, also called a <strong>two-way factorial design</strong>.</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Activity: Visualizing the Data {‑}
&gt;3. Use Figure 4.1 to compare the for each of the four factor-level combinations. Do the four groups appear to have similar means or similar standard deviations? Are there any outliers (extreme observations that don’t seem to fit the rest of the data)? Describe any patterns you see in the data.<br>
4. Calculate the average <em>PopRate</em> for each <em>Brand</em> and each <em>Time</em>. Calculate the overall average <em>PopRate</em>.<br>
5. Use the data set labeled <code>Popcorn</code> to calculate appropriate summary statistics (the median, mean, standard deviation, range, etc.) for each of the four groups. For the Fastco brand, calculate the difference between the average <em>PopRate</em> for the two cooking times. Do the same for the Pop Secret brand.</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Notation for Multiple Explanatory Variables {‑}</p>
<p>Table 4.2 shows the <code>Popcorn</code> data set organized by the <em>Brand</em> and <em>Time</em> factors. Each of the four treatment combinations has eight observations. The data are also provided in the file <code>Popcorn</code>.</p>
<div class="figure">
<img src="Chap4_files/figure-html/fig4.1-1.png" alt="Figure 4.1 Individual value plot of the PopRate (100 $ imes$ count of popped kernels/total kernels) for each Brand and cooking Time factor-level combination. Points have jittering (small fluctuations) so that all values are visible." width="576"><p class="caption">
(#fig:fig4.1)Figure 4.1 Individual value plot of the PopRate (100 $ imes$ count of popped kernels/total kernels) for each Brand and cooking Time factor-level combination. Points have jittering (small fluctuations) so that all values are visible.
</p>
</div>
<p>Table 4.3 is useful in visualizing the differences and similarities among the meaningful groups within this data set: the overall average, the two <em>Brand</em> groups, the two <em>Time</em> groups, and the four factor-level combinations. Table 4.3 also includes mathematical notation representing each mean. For example, <span class="math inline">\(\bar{y}_{11}\)</span> represents the mean of the 8 responses from the first <em>Brand</em>, Fastco, and the first <em>Time</em> group, 105 seconds. <span class="math inline">\(\bar{y}_{2.}\)</span> represents the mean of the 16 responses from the second <em>Brand</em> group, Pop Secret. <span class="math inline">\(\bar{y}_{..}\)</span> represents the overall mean of all 32 responses.</p>
<p><br>
The dot in the subscript indicates that the average was taken over all values of that subscript. The key is to recognize that groups are identified by their subscripts. <em>Brand</em> is the first subscript, and <em>Time</em> is the second. Each individual observation for each <em>Brand</em> and <em>Time</em> factor-level combination is represented by the third subscript. For example, the 4th observation in Table 4.2 for the Fastco brand (brand 1) and the 135-second time (time 2) group is <span class="math inline">\(y_{124} = 71.50\)</span>. The average of the 8 observations in the Fastco brand (brand 1) and 135-second time group is represented by <span class="math inline">\(\bar{y}_{12} = 82.38\)</span>. In addition, <span class="math inline">\(\bar{y}_{1.}\)</span> is the average response of all 16 of the Fastco brand (brand 1) observations, while <span class="math inline">\(\bar{y}_{.1}\)</span> is the average response of all 16 of the 105-second times (time 1 observations). <span class="math inline">\(\bar{y}_{..}\)</span> is the average <em>PopRate</em>, averaged over all observations for both <em>Brand</em> and cooking <em>Time</em>. That is, <span class="math inline">\(\bar{y}_{..}\)</span> is the overall average <em>PopRate</em>.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Activity: Understanding Notation {‑}
&gt;6. Which notation would be used to describe the sample average of the 135-second group?<br>
7. Explain the difference between <span class="math inline">\(\bar{y}_{21}\)</span> and <span class="math inline">\(\bar{y}_{12}\)</span>.</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Comparing Variances* {‑} <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;If you have studied ANOVA tables before, you may find it surprising that we focus on mean squares (MS) and do not discuss sums of squares (SS) or degrees of freedom (df). The focus of this section is the concepts and logic behind ANOVA. ANOVA is the process of comparing between group and within group variability. These types of variability are represented by the mean squares. Chapter 2 and the extended activities discuss sums of squares and degrees of freedom.&lt;/p&gt;"><sup>3</sup></a></p>
<p>Figure 4.1 and Table 4.3 indicate that the difference between the <em>Time</em> means is much larger than the difference between the <em>Brand</em> means. In addition, the difference between <em>Time</em> means is much larger for the Pop Secret brand than for the Fastco brand. In this section, we will conduct an analysis, called analysis of variance, to find <span class="math inline">\(p\)</span>-values for testing each of the three hypotheses stated earlier about the underlying mean responses.</p>
<p>Analysis of variance (ANOVA) is conducted by comparing the variability between groups to the variability within groups. For example, does the variability between <em>Brand</em> means (between groups) appear to be large compared to the variation of responses within the two <em>Brand</em> levels (within groups)? In ANOVA, these measures of variability are called mean squares. For example, the variability between brands is called mean square brand and is denoted <span class="math inline">\(MS_{\text{Brand}}\)</span>. In actual practice, the following ANOVA calculations are done with computer software instead of by hand. The reason for working through these equations in detail is to better illustrate the logic behind using ANOVA to determine if between group variability is significant (i.e., to determine whether we can reject any of the null hypotheses).</p>
<p><strong>Between-Group Variability</strong> To create a measure of the variability between <em>Brand</em> means (<span class="math inline">\(MS_{\text{Brand}}\)</span>) calculate the weighted variance of the <em>Brand</em> group means, using the size of each group as the weight. The weighted variance of the <em>Brand</em> group means is calculated with the following equation:</p>
<p><span class="math display">\[\begin{align}
MS_{\text{Brand}} = \frac{\sum_{i=1}^{2} n_i \times (\bar{y}_{i.} - \bar{y}_{..})^2}{2-1}
\notag
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
= \frac{16 \times (81.8 - 81.3)^2 + 16 \times (80.9 - 81.3)^2}{2-1}
\tag{4.1}
\end{align}\]</span></p>
<p>where <span class="math inline">\(n_i\)</span> is the number of observations for brand <span class="math inline">\(i\)</span>. In this study, <span class="math inline">\(n_i = 16\)</span> observations are taken for each brand. Notice that Equation (4.1) looks similar to a typical variance calculation:</p>
<ul>
<li>There are two observed group means: 81.8 and 80.9.</li>
<li>The spread is measured by summing the squared distance between each observed group mean and the overall mean and then dividing by the number of group means minus one.</li>
</ul>
<p>As with any variance calculation, we are finding an average squared distance (mean squared distance, denoted <span class="math inline">\(MS_{\text{Brand}}\)</span>). The difference between this calculation and a typical variance calculation is the use of weights:</p>
<ul>
<li>Each observed mean is based on a group of size 16; this group sample size (<span class="math inline">\(n_i = 16\)</span>) is multiplied by each squared distance.</li>
</ul>
<p><br>
In our study, we have a balanced design (i.e., equal sample sizes in every group). However, the formulas throughout this section allow for studies with unequal sample sizes (called unbalanced designs).
</p>
<p>The calculation of the variability between the <em>Time</em> means (<span class="math inline">\(MS_{\text{Time}}\)</span>) is very similar to Equation (4.1):</p>
<p><span class="math display">\[\begin{align}
MS_{\text{Time}} = \frac{\sum_{j=1}^{2} n_j \times (\bar{y}_{.j} - \bar{y}_{..})^2}{2-1}
\tag{4.2}
\end{align}\]</span></p>
<p>The first two hypotheses at the beginning of this section correspond to questions about main factors incorporated into the experiment, <em>Brand</em> and <em>Time</em>. The third hypothesis focuses on whether the impact of one variable (<em>Time</em>) depends on a second variable (<em>Brand</em>). This is called an interaction effect.</p>
<p>Table 4.3 provides some evidence of interaction between <em>Brand</em> and <em>Time</em>. For the Fastco brand popcorn, the longer cooking time increases the percentage of popped kernels by <span class="math inline">\(\bar{y}_{12.} - \bar{y}_{11.} = 82.38 - 81.13 = 1.25\)</span>, while the increase for the Pop Secret brand is many times larger: <span class="math inline">\(\bar{y}_{22.} - \bar{y}_{21.} = 86.42 - 75.44 = 10.98\)</span>.</p>
<p>To test for an interaction effect (the third hypothesis), we first measure the variability between all four groups (each <em>Brand</em> and <em>Time</em> combination) and then subtract the squared values for the main factors.</p>
<p><span class="math display">\[\begin{align}
MS_{\text{BrandTime}} = \frac{\sum_{i=1}^{2}\sum_{j=1}^{2} n_{ij}(\bar{y}_{ij.} - \bar{y}_{..})^2 - \sum_{i=1}^{2} n_{i.}(\bar{y}_{i.} - \bar{y}_{..})^2 - \sum_{j=1}^{2} n_{.j}(\bar{y}_{.j} - \bar{y}_{..})^2}{4 - 1 - 1 - 1}
\tag{4.3}
\end{align}\]</span></p>
<p>The key aspect of Equation (4.3) is that it calculates the squared distance between the four factor-level group means and the overall mean after accounting for the main factor group means. Thus, this calculation is an estimate of how spread out the four group means are after accounting for any influence of the main factor means.</p>
<p>The denominator of the mean square for interaction is based on the denominators from <span class="math inline">\(MS_{\text{Brand}}\)</span> in Equation (4.1) and <span class="math inline">\(MS_{\text{Time}}\)</span> in Equation (4.2). In this example, there are four factor-level group means. Thus, the denominator is calculated as <span class="math inline">\(4 - 1 -\)</span> (denominator from <span class="math inline">\(MS_{\text{Brand}}\)</span>) <span class="math inline">\(-\)</span> (denominator from <span class="math inline">\(MS_{\text{Time}}\)</span>) <span class="math inline">\(= 4 - 1 - 1 - 1\)</span>. Details for deriving mean squares are provided in the extended activities.</p>
<p><br>
The interaction term is not simply a measure of the spread between the four factor-level group means. It measures the remaining spread of the means after adjusting for differences between the main factor means.
</p>
<p><strong>Within-Group Variability</strong> The best estimate of the variability within each group (MSE) is simply a weighted average of the sample variances within each of the four factor-level groups:</p>
<p><span class="math display">\[\begin{align}
\text{MSE} &amp;=
\frac{\sum_{i=1}^{2}\sum_{j=1}^{2}(n_{ij} - 1)s_{ij}^2}{(n_{11} - 1) + (n_{12} - 1) + (n_{21} - 1) + (n_{22} - 1)} \notag \\
&amp;= \frac{(8 - 1)s_{11}^2 + (8 - 1)s_{12}^2 + (8 - 1)s_{21}^2 + (8 - 1)s_{22}^2}
{(8 - 1) + (8 - 1) + (8 - 1) + (8 - 1)}
\tag{4.4}
\end{align}\]</span></p>
<p>where <span class="math inline">\(s_{ij}^2\)</span> is the sample variance for the group representing brand <span class="math inline">\(i\)</span> and time <span class="math inline">\(j\)</span>. The implicit assumption here is that the variances of the possible responses with each of the four group populations are all the same, so it makes sense to “pool” the sample variances into a single estimate of overall response variability. This <strong>equal variance assumption</strong> is key to the validity of the ANOVA statistical method. If the variability within each group is quite different, the MSE may not be an appropriate estimate. It is often useful to create individual value plots or side-by-side boxplots of the groups to check if the spreads of the sample groups are roughly similar.</p>
<p><br>
If groups of data from each factor-level combination have very different sample sizes and at least one group has a small sample size (e.g., less than 5 units per group), then ANOVA may not be appropriate. If the group(s) with the smallest sample size (s) has an unusually high variance, the MSE is likely to underestimate the true variance and ANOVA is likely to incorrectly reject the null hypothesis (conclude that there are differences when there really are no differences between group means). If the group(s) with the smallest sample size(s) has an unusually small variance, the <strong>MSE</strong> is likely to overestimate the true variance. The larger MSE may cause us to incorrectly fail to reject the null hypothesis (fail to detect true differences).
</p>
<p>Equation (4.4) is often called the <strong>mean square error</strong> (MSE) of the responses, because “error” represents the unit-to-unit variability in the response that can’t be explained by any of the main factors or interactions. We are now ready to calculate a test statistic corresponding to each of the three hypotheses at the beginning of this section.</p>
<p><strong>The F-Statistic</strong> The F-statistic is a ratio of the between-group variability (variation between factor-level averages) to the within-group variability (pooled estimate of variability within each factor-level combination): (MS for factor)/MSE. Mathematical theory proves that if the assumptions of the ANOVA model hold, the F-statistic follows an F-distribution with degrees of freedom corresponding to the denominators of the MS for the factor being tested and the MSE. The <span class="math inline">\(p\)</span>-value gives the likelihood of observing an F-statistic at least this large, assuming that the true population factor has equal level means. Thus, when the <span class="math inline">\(p\)</span>-value is small, we conclude that there is a difference between the level means. Additional details are provided in the extended activities at the end of the chapter.</p>
<p><br>
An F-statistic is simply the ratio of the between-group variability to the within-group variability.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Activity: Calculating F-Statistics {‑}
&gt;8. Use Equation (4.1) to estimate <span class="math inline">\(MS_{\text{Brand}}\)</span>, the variability between <em>Brand</em> means.<br>
9. Calculate the variability between <em>Time</em> means, <span class="math inline">\(MS_{\text{Time}}\)</span>. Explain the key differences between Equation (4.1) and Equation (4.2).<br>
10. Use Equation (4.3) to estimate <span class="math inline">\(MS_{\text{BrandTime}}\)</span>.<br>
11. Calculate the <span class="math inline">\(F\)</span>-statistics corresponding to the three hypothesis tests: <span class="math inline">\(\frac{MS_{\text{Brand}}}{\text{MSE}}\)</span>, <span class="math inline">\(\frac{MS_{\text{Time}}}{\text{MSE}}\)</span>, <span class="math inline">\(\frac{MS_{\text{BrandTime}}}{\text{MSE}}\)</span>.<br>
12. What do you think are the largest and smallest possible values of any <span class="math inline">\(F\)</span>-statistic?<br>
13. Use the technology instructions provided on the CD to check your answers. Submit the software output. Note that a <span class="math inline">\(p\)</span>-value for each <span class="math inline">\(F\)</span>-statistic is provided. State your conclusions about each of the three hypotheses based on these <span class="math inline">\(p\)</span>-values.<br>
Don’t be surprised if your hand calculations in Question 11 differ somewhat from the software output here. The data in Table 4.3 were rounded to one decimal place, so calculations in Questions 8 through 11 are not as accurate as statistical software.<br>
14. Explain why a large <span class="math inline">\(F\)</span>-statistic corresponds to a small <span class="math inline">\(p\)</span>-value by referring to the definition of an <span class="math inline">\(F\)</span>-statistic: a ratio of between-group variability to within-group variability.<br>
15. <strong>Checking Assumptions</strong> As described in Chapter 2, assumptions need to be checked to ensure that the <span class="math inline">\(p\)</span>-value for each ANOVA <span class="math inline">\(F\)</span>-test is reliable:
- The observations within each group (each factor-level combination) are independent and identically distributed.
- Each group has equal variances.
- The residual values follow a normal distribution with a mean of zero.
a. Examine the individual value plot in Figure 4.1 and comment on the assumptions for these hypothesis tests. Is there evidence of any skewness or outliers that may cause us to doubt the normal assumption for the <em>PopRate</em> within each factor-level combination of <em>Brand</em> and <em>Time</em>?
b. Does Figure 4.1 indicate that the spread of each group appears roughly similar, so the equal variance assumption seems reasonable? Another informal check of the equal variance assumption can be done by calculating the ratio of the maximum sample standard deviation to the minimum sample standard deviation. If this ratio is less than two, we can generally assume that there is not strong evidence against the equal variance assumption. Compare the standard deviations of the four treatment level combinations to determine if
<span class="math display">\[\begin{align}
\frac{\max(s_{ij})}{\min(s_{ij})} &lt; 2
\notag
\end{align}\]</span>
c. Create a normal probability plot or histogram of the residuals from Question 13. Does it appear that the residuals follow a normal distribution?</p>
<p><br>
Some statisticians will reject the equal variance assumption when the ratio of standard deviations is greater than 3 instead of 2. Others recommend that formal tests be used to test for equal variances. However, some tests, such as Bartlett’s test, are very sensitive to nonnormality. Box criticized using Bartlett’s test as a preliminary test for equal variances, saying, “To make the preliminary test on variances is rather like putting to sea in a rowing boat to find out whether conditions are sufficiently calm for an ocean liner to leave port.”<span class="math inline">\(^4\)</span> Levene’s test of homogeneity of variance is less sensitive to departures from normality.<span class="math inline">\(^5\)</span>
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Interpreting Interaction Terms {-}</p>
<p>In Question 13, the <span class="math inline">\(p\)</span>-value corresponding to the third hypothesis test listed at the beginning of this section was 0.04. This demonstrates an interaction: the effect of one variable (<em>Time</em>) on the response depends on a second variable (<em>Brand</em>). Figure 4.2 provides a side-by-side boxplot and an interaction plot of the <em>Popcorn</em> data. <strong>An interaction plot</strong> is simply a plot of the four factor-level group means shown in Table 4.3. These plots show that for both brands, the average <em>PopRate</em> increases when the cooking time changes from 105 to 135 seconds. However, the change in means for the Fastco brand is very small compared to the change observed in the Pop Secret brand.</p>
<div class="figure">
<img src="Chap4_files/figure-html/fig4.2-1.png" alt="Figure 4.2 Side-by-side boxplots and an interaction plot of the PopRate for each Brand and cooking Time factor-level combination." width="576"><p class="caption">
(#fig:fig4.2)Figure 4.2 Side-by-side boxplots and an interaction plot of the PopRate for each Brand and cooking Time factor-level combination.
</p>
</div>
<p>The interaction plot is helpful in visualizing how the effect of one factor can depend on another factor, especially when there are multiple factors in the study. When the lines in an interaction plot are essentially parallel, the effect of the first variable is not influenced by a second variable. Nonparallel lines indicate an interaction between main factors (e.g., the effect of <em>Time</em> depends on <em>Brand</em>). However, the interaction plot does not show the within group variability, so only the <span class="math inline">\(p\)</span>-value from the ANOVA can be used to determine if the interaction is significant. The <span class="math inline">\(p\)</span>-value of 0.04 shows that the observed interaction effect is so large that it is unlikely to have occurred just by chance. We conclude that <span class="math inline">\(H_{a,3}\)</span> is true: <em>Brand</em> influences the effect of <em>Time</em> on <em>PopRate</em>.</p>
</div>
<div id="analyzing-a-three-way-factorial-design" class="section level2" number="4.6">
<h2>
<span class="header-section-number">4.6</span> <strong>Analyzing a Three-Way Factorial Design</strong><a class="anchor" aria-label="anchor" href="#analyzing-a-three-way-factorial-design"><i class="fas fa-link"></i></a>
</h2>
<p>One advantage of ANOVA is that the analysis can easily be extended to multiple factors with many levels. In this section, all three factors in the popcorn study (<em>Brand</em>, <em>Time</em>, and <em>Microwave</em>) will be simultaneously examined for their influence on <em>PopRate</em> with a three-way ANOVA (also called a three-factor ANOVA).</p>
<p>Using only the 32 observations from the <em>Popcorn</em> data, a three-way ANOVA will allow us to simultaneously test the following six hypotheses:</p>
<ol style="list-style-type: decimal">
<li>
<p><span class="math inline">\(H_{0,1}: \mu_{\text{Fastco}} = \mu_{\text{PopSecret}}\)</span></p>
<p><span class="math inline">\(H_{a,1}: \mu_{\text{Fastco}} \ne \mu_{\text{PopSecret}}\)</span></p>
</li>
<li>
<p><span class="math inline">\(H_{0,2}: \mu_{105} = \mu_{135}\)</span></p>
<p><span class="math inline">\(H_{a,2}: \mu_{105} \ne \mu_{135}\)</span></p>
</li>
<li>
<p><span class="math inline">\(H_{0,3}\)</span>: <em>Brand</em> has no influence on how <em>Time</em> affects <em>PopRate</em></p>
<p><span class="math inline">\(H_{a,3}\)</span>: there is an interaction between <em>Brand</em> and <em>Time</em></p>
</li>
<li>
<p><span class="math inline">\(H_{0,4}: \mu_{\text{Room}} = \mu_{\text{Lounge}}\)</span></p>
<p><span class="math inline">\(H_{a,4}: \mu_{\text{Room}} \ne \mu_{\text{Lounge}}\)</span></p>
</li>
<li>
<p><span class="math inline">\(H_{0,5}\)</span>: <em>Microwave</em> has no influence on how <em>Brand</em> affects <em>PopRate</em></p>
<p><span class="math inline">\(H_{a,5}\)</span>: there is an interaction between <em>Microwave</em> and <em>Brand</em></p>
</li>
<li>
<p><span class="math inline">\(H_{0,6}\)</span>: <em>Microwave</em> has no influence on how <em>Time</em> affects <em>PopRate</em></p>
<p><span class="math inline">\(H_{a,6}\)</span>: there is an interaction between <em>Microwave</em> and <em>Time</em></p>
</li>
</ol>
<p><br>
It is also reasonable to test for a three-way interaction. <span class="math inline">\(H_{a,7}\)</span>, the size of the effect of <em>Time</em> for each level of <em>Brand</em>, also depends on a third variable, <em>Microwave</em>. In practice, the three-way interaction effect may be difficult to interpret and some researchers choose not to include them in their analysis. The impacts of including additional tests are described in Chapter 5.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Activity: Conducting a Three-Way ANOVA {‑}
&gt;16. Create individual value plots of the eight possible factor-level groups listed in Table 4.1.
a. Do you see any patterns in the <em>PopRate</em> among these groups?
b. Does the spread of the responses within each group look roughly similar?
c. Are there any outliers or unusual observations for any group(s)?
17. Calculate the eight group standard deviations. If the largest standard deviation is no more than two times the smallest standard deviation, it is typically appropriate to assume equal variances for the population of responses within each group. Is it appropriate to assume equal variances in this <em>Popcorn</em> study?
18. Use a statistical software package to simultaneously test all six hypotheses given at the beginning of this section.
a. Submit the appropriate software output.
b. Create a normal probability plot (described in Chapter 2) or a histogram of the residuals. Are the residuals consistent with the assumption of a normal distribution?
c. Use the <span class="math inline">\(p\)</span>-value corresponding to each hypothesis to state your conclusions.
d. Address how random sampling and random allocation influence your conclusions.
19. Determine whether <span class="math inline">\(MS_{\text{Brand}}\)</span>, <span class="math inline">\(MS_{\text{Time}}\)</span>, and <span class="math inline">\(MS_{\text{BrandTime}}\)</span> are the same as in Question 13. Explain why the <span class="math inline">\(F\)</span>-statistics corresponding to these three hypotheses have changed.</p>
<p>In completely randomized designs, all <span class="math inline">\(F\)</span>-statistics corresponding to the tests for each main factor and interaction use the same denominator. The mean square for each main factor (<span class="math inline">\(MS_{\text{Brand}}\)</span>, <span class="math inline">\(MS_{\text{Time}}\)</span>, and <span class="math inline">\(MS_{\text{Microwave}}\)</span>) is a measurement of the variability between level means. Since this is a balanced design, when the level means for a factor are farther apart, the corresponding mean square and <span class="math inline">\(F\)</span>-statistics are larger. Thus, the main effects plot shown in Figure 4.3 allows us to quickly see that the <em>Time</em> factor is the most significant (has the smallest <span class="math inline">\(p\)</span>-value) and the <em>Brand</em> factor is the least significant.</p>
<div class="figure" style="text-align: center">
<img src="docs/Fig4_3MainInteractionPlots.jpg" alt="Main effect plots and interaction plots for a three-factor ANOVA." width="80%"><p class="caption">
(#fig:fig4.3)Main effect plots and interaction plots for a three-factor ANOVA.
</p>
</div>
<p>Figure 4.3 also provides interaction plots corresponding to the three hypotheses tests about interactions. Using the same logic, Figure 4.3 shows that the hypothesis test corresponding to the <em>Brand</em> and <em>Time</em> interaction will have the smallest <span class="math inline">\(p\)</span>-value. While both the effect of <em>Time</em> and the effect of <em>Brand</em> are somewhat influenced by <em>Microwave</em>, the effect of <em>Time</em> is most influenced by changing <em>Brand</em>.</p>
</div>
<div id="what-can-we-conclude-from-the-popcorn-study" class="section level2" number="4.7">
<h2>
<span class="header-section-number">4.7</span> <strong>What Can We Conclude from the Popcorn Study?</strong><a class="anchor" aria-label="anchor" href="#what-can-we-conclude-from-the-popcorn-study"><i class="fas fa-link"></i></a>
</h2>
<p>Yvonne and Tue’s study illustrated how essential it is to carefully plan out a study before any data are collected. If the data are not collected properly, typically there is <em>no</em> statistical analysis that can draw accurate conclusions. When the study is well designed and the data are reliable, analysis is often straightforward with statistical software.</p>
<p>The units in this study (<em>Bags</em>) were randomly assigned to <em>Time</em> and <em>Microwave</em> factor-level combinations. The ANOVA results allowed us to conclude that <em>Time</em> causes a difference in <em>PopRate</em>. In addition, we found evidence that there is a <em>Brand</em> and <em>Time</em> interaction.</p>
<p>The bags of popcorn in this study were not a true random sample of all popcorn produced by these two brands. Thus, we need to be careful about making any conclusions that extend to a larger population. Because of the efforts the students made to properly collect random samples from various stores around their college town, the author of this chapter would feel fairly comfortable stating that the conclusions hold for these two brands of butter-flavored microwave popcorn in their town at the time of this study.</p>
<p><br>
Recall that random sampling is needed to extend the results to a larger population. If the students randomly sampled 26 towels from just one roll, the conclusions would hold only for that roll. Ideally they should have randomly purchased 26 rolls of each brand from multiple locations and then randomly selected one towel per roll.
</p>
</div>
<div id="paper-towels-developing-a-statistical-model-for-a-two-way-factorial-design" class="section level2" number="4.8">
<h2>
<span class="header-section-number">4.8</span> <strong>Paper Towels: Developing a Statistical Model for a Two-Way Factorial Design</strong><a class="anchor" aria-label="anchor" href="#paper-towels-developing-a-statistical-model-for-a-two-way-factorial-design"><i class="fas fa-link"></i></a>
</h2>
<p>As a final project in an introductory statistics class, several students decided to conduct a study to test the strength of paper towels. Several television advertisements had claimed that a certain brand of paper towel was the strongest, and these students wanted to determine if there really was a difference. The students sampled 26 towels from two brands of paper towels, Comfort and Decorator.</p>
<p>Before any data were collected, these students determined that the following conditions should be held as constant as possible throughout the study:</p>
<ul>
<li>Paper towels were selected that had the same size.</li>
<li>The towels were held at all four corners by two people.</li>
<li>Weights (10, 25, 50, 100, or 250 grams) were slowly added to the center of each towel by a third person until it broke.</li>
</ul>
<p>In this study, there are two factors. One has two levels, Comfort (Brand C) or Decorator (Brand D), and the other has three levels (0, 5, or 15 drops of water applied to the center of the paper towel). This leads to <span class="math inline">\(2 \times 3 = 6\)</span> conditions, called <strong>factor-level combinations</strong> or <strong>factorial combinations</strong>:</p>
<p>Brand C and 0 drops of water<br>
Brand C and 5 drops of water<br>
Brand C and 15 drops of water<br>
Brand D and 0 drops of water<br>
Brand D and 5 drops of water<br>
Brand D and 15 drops of water</p>
<p>Twenty-six sheets were tested at each of the six factor-level combinations. Thus, there are 156 experimental units used in this study. The response variable is the breaking strength of each paper towel in grams. Breaking strength is defined as the total weight that each towel successfully held. The next additional weight caused the towel to break.</p>
<p>The three null hypotheses corresponding to this two-factor design are as follows:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(H_{0,1}\)</span>: there is no difference in mean strength between the two brands of towel<br><span class="math inline">\(H_{a,1}\)</span>: the two brand means are different</p></li>
<li><p><span class="math inline">\(H_{0,2}\)</span>: there is no difference in mean strength when 0, 5, or 15 drops of water are used<br><span class="math inline">\(H_{a,2}\)</span>: the mean strength of at least one water amount group is different from the others</p></li>
<li><p><span class="math inline">\(H_{0,3}\)</span>: the amount of water has no influence on how brand affects strength<br>
or <span class="math inline">\(H_{0,3}\)</span>: the effect of the amount of water on strength is the same for both brands<br>
or <span class="math inline">\(H_{0,3}\)</span>: there is no interaction between brand and water<br><span class="math inline">\(H_{a,3}\)</span>: there is an interaction between brand and water</p></li>
</ol>
<p>Table 4.4 represents some of the data for the paper towel study. Each of the six cells has 26 observations. The complete data set is in the file <code>PaperTowels</code>. While not all observations are shown, Table 4.4 helps us understand the data structure. After the data have been collected, the averages for all meaningful groups of the data can be calculated as shown in Table 4.5.</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Extended Activity: Algebraic Notation {‑}
&gt;Data set: <span class="math inline">\(PaperTowels\)</span><br>
20. What values in Table 4.4 are represented by <span class="math inline">\(y_{213}\)</span> and <span class="math inline">\(y_{122}\)</span>?<br>
21. Give the proper algebraic notation for the observation representing the 3rd paper towel with Brand D
and 15 drops of water.<br>
22. What are the values of <span class="math inline">\(\bar{y}_{.3.}\)</span> and <span class="math inline">\(\bar{y}_{21.}\)</span>?<br>
23. Complete Table 4.5 by calculating the three missing averages.</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Calculating Effects {‑}</p>
<p>As the data structure becomes more complex, a statistical model becomes more useful for describing the population(s) from which the data may have come. Generally, statistical models consist of a mean response and a random error term (details are provided in Chapter 2). The mean response describes the expected (mean) breaking strength. Figure 4.4 is useful in visualizing the meaningful groups within this model that contribute to the mean response of the model: the grand mean, the two brand groups, the three water amount groups, and the six factor-level combination groups.</p>
<p>The random error term follows an overall pattern that can be modeled with a probability distribution (e.g., the normal distribution). The error term incorporates the reality that observations will vary within each factor-level combination. Even when the same weights are applied to the same brand of paper towel, using the same water amount, the observed breaking strength may not be the same.</p>
<p>The labels (e.g., the grand mean, group effects, and random errors) and symbols in Figure 4.4 are described below:</p>
<p><span class="math inline">\(y_{ijk}\)</span>: the <span class="math inline">\(k\)</span>th observed breaking strength (<span class="math inline">\(k = 1, 2, \ldots, 26\)</span>) for brand <span class="math inline">\(i\)</span> and water amount <span class="math inline">\(j\)</span><br><span class="math inline">\(\mu\)</span>: overall mean breaking strength of the entire population of paper towels across brands and water amounts (also called the grand mean)<br><span class="math inline">\(\alpha_i\)</span>: brand effect (<span class="math inline">\(i = 1, 2\)</span>), where <span class="math inline">\(\alpha_1\)</span> is the effect of Brand C and <span class="math inline">\(\alpha_2\)</span> is the effect of Brand D<br><span class="math inline">\(\beta_j\)</span>: amount of water effect (<span class="math inline">\(j = 1, 2, 3\)</span>), where <span class="math inline">\(\beta_1\)</span> represents the effect of 0 drops of water<br><span class="math inline">\((\alpha\beta)_{ij}\)</span>: interaction effect, where <span class="math inline">\((\alpha\beta)_{23}\)</span> represents the Brand D/15 drops of water interaction effect<br><span class="math inline">\(\varepsilon_{ijk}\)</span>: the random error—the difference between the <span class="math inline">\(k\)</span>th observed value (<span class="math inline">\(k = 1, 2, \ldots, 26\)</span>) and the population mean breaking strength for brand <span class="math inline">\(i\)</span> and water amount <span class="math inline">\(j\)</span></p>
<div class="figure" style="text-align: center">
<img src="docs/Fig4_4TwoWayDiagram.jpg" alt="Two-way factorial diagram." width="80%"><p class="caption">
(#fig:fig4.4)Two-way factorial diagram.
</p>
</div>
<p>Notice that each of the <span class="math inline">\(2 \times 3 \times 26 = 156\)</span> observed strength measurements represents one of the 156 equations in Figure 4.4. The structure of the data is now used to write down a statistical model for the data:
<span class="math display">\[\begin{align}
y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk} \quad \text{for } i = 1,2,\ j = 1,2,3, \text{ and } k = 1,2,\ldots,26 \tag{4.5}
\end{align}\]</span></p>
<p>
Identifying the meaningful groups within each data set (the data structure) is the first step in developing a statistical model of the population(s) from which the data come.
</p>
<p>Table 4.5 shows that the <em>Strength</em> average changes from 1772.8 to 1123.4 with a change from Brand C to Brand D paper towels. This difference is smaller than the differences due to changes in the water amount. <strong>Main effects</strong> are calculated to measure the impact of changing the levels of each factor in the model. A main effect is the difference between the factor-level average and the grand mean. For example,</p>
<p><span class="math display">\[\begin{align}
\hat{\alpha}_1 &amp;= \text{effect of Brand C} = \text{Brand C mean} - \text{grand mean} \notag \\
&amp;= \bar{y}_{1.} - \bar{y}_{..} = 1772.8 - 1448.1 = 324.7 \notag
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\hat{\beta}_3 &amp;= \text{effect of 15 drops of water} = \text{15 drops mean} - \text{grand mean} \notag \\
&amp;= \bar{y}_{.3} - \bar{y}_{..} = 423.6 - 1448.1 = -1024.5 \tag{4.6}
\end{align}\]</span></p>
<p><br><span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha_i\)</span>, <span class="math inline">\(\beta_j\)</span>, and <span class="math inline">\((\alpha\beta)_{ij}\)</span> in Equation (4.5) are population parameters. Statistics such as <span class="math inline">\(\hat{\alpha}_i\)</span> and <span class="math inline">\(\hat{\beta}_j\)</span> in Equation (4.6) are used to estimate the population effect sizes.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Extended Activity: Estimating Main Effects {‑}
&gt;Data set: PaperTowels<br>
24. Use the <code>PaperTowels</code> data to estimate the effect of Brand D and explain any symmetry that you find with the effect of Brand C calculated above.<br>
25. A <strong>main effects plot</strong> is a graph that plots the average response for each level of each factor. To properly compare the effect sizes, the vertical axis should be the same for each factor. Use statistical software to create a main effects plot. Identify and label the following values on the plot: <span class="math inline">\(\bar{y}_{1.}\)</span>, <span class="math inline">\(\bar{y}_{.3}\)</span>, <span class="math inline">\(\bar{y}_{..}\)</span>, <span class="math inline">\(\hat{\alpha}_1\)</span>, and <span class="math inline">\(\hat{\beta}_3\)</span>.</p>
<p><br>
This is still a balanced design, since <span class="math inline">\(n_{ij}\)</span> is the same for each factor-level combination. However, since the sample sizes are not the same in every group level (78 towels for each brand mean and 52 towels for each water level), the factor with the largest difference between means does not necessarily correspond to the smallest <span class="math inline">\(p\)</span>-value.
</p>
<p>In addition to determining the main effects for each factor, it is often critical to identify how multiple factors interact in affecting the results. An interaction occurs when one factor affects the response variable differently depending on a second factor. To calculate the effect of the brand and water interaction, take the average for a particular factor combination minus the grand mean and the corresponding main effects.</p>
<p>Interaction effect of Brand C and 15 drops of water interaction effect<br>
= average of Brand C, 15 drops group<br>
- (effect of Brand C + effect of 15 drops + grand mean)<br><span class="math inline">\(= \bar{y}_{13.} - [\hat{\alpha}_1 + \hat{\beta}_3 + \bar{y}_{..}]\)</span><br><span class="math inline">\(= \bar{y}_{13.} - [(\bar{y}_{1.} - \bar{y}_{..}) + (\bar{y}_{.3} - \bar{y}_{..}) + \bar{y}_{..}]\)</span><br><span class="math inline">\(= 401.0 - [324.7 + (-1024.5) + 1448.1]\)</span><br><span class="math inline">\(= -347.3\)</span> (4.7)</p>
<p>The estimate of the Brand C and 15 drops of water interaction effect in Equation (4.7) tells us that the best estimate of any paper towel strength from this group should be reduced by an additional 347.3 after we take into account all other influencing factors (the grand mean and main effects).</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Activity: Calculating Interaction Effects {‑}
&gt;Data set: <span class="math inline">\(PaperTowels\)</span><br>
26. Show that <span class="math inline">\(\bar{y}_{ij.} - \bar{y}_{i.} - \bar{y}_{.j} + \bar{y}_{..}\)</span> is equivalent to the <span class="math inline">\(j\)</span>th interaction effect.<br>
27. Calculate the other five interaction effects. Hand draw Figure 4.4 and fill out the effect sizes with observed values (i.e., replace <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha_i\)</span>, <span class="math inline">\(\beta_j\)</span>, and <span class="math inline">\((\alpha\beta)_{ij}\)</span> with estimates from the data). Do not fill out the observations or the error terms (<span class="math inline">\(y_{ijk}\)</span> or <span class="math inline">\(\varepsilon_{ijk}\)</span>).<br>
28. Create an interaction plot. Does there appear to be evidence of an interaction effect?<br>
29. Draw a diagram similar to Figure 4.4 for a two-way factorial design with four levels of the first factor, three levels of the second factor, and two observations per factor-level combination in Equation (4.5).<br>
30. Residuals, or observed random error terms, are defined as the observed responses, <span class="math inline">\(y_{ijk}\)</span>, minus the estimate for the mean response (the sum of the grand mean, the two main effects, and the interaction effect). Calculate the residual values for <span class="math inline">\(y_{213}\)</span> and <span class="math inline">\(y_{122}\)</span>.</p>
<p>The effect for Brand C might be positive (Brand C has a higher average breaking strength than Brand D), but then the effect for Brand D must be negative and exactly the same size as the effect for Brand C. The two effects sum to zero. This is called a <strong>restriction</strong> on the model terms. The entire set of restrictions for the model in Equation (4.5) is provided below.</p>
<p><span class="math display">\[\begin{align}
\sum_{i=1}^{2} \alpha_i = \alpha_1 + \alpha_2 = 0, \qquad \sum_{j=1}^{3} \beta_j = \beta_1 + \beta_2 + \beta_3 = 0 \notag
\end{align}\]</span>
<span class="math display">\[\begin{align}
\sum_{i=1}^{2} (\alpha\beta)_{ij} = (\alpha\beta)_{1j} + (\alpha\beta)_{2j} = 0 \quad \text{for all } j \notag \\
\sum_{j=1}^{3} (\alpha\beta)_{ij} = (\alpha\beta)_{i1} + (\alpha\beta)_{i2} + (\alpha\beta)_{i3} = 0 \quad \text{for all } i \tag{4.8}
\end{align}\]</span></p>
<p>More specifically, the restrictions state that the interaction effects involving Brand C must sum to zero (i.e., <span class="math inline">\((\alpha\beta)_{11} + (\alpha\beta)_{12} + (\alpha\beta)_{13} = 0\)</span>). In the same way, all interactions corresponding to the 15 drops of water groups must also sum to zero. All six restrictions corresponding to the interactions can be checked in Question 27. The residual values sum to zero within each group of interest. This will always be true whenever calculating effects. This is not surprising, since effects measure the deviation of a particular group mean from the overall mean.</p>
</div>
<div id="paper-towels-the-relationship-between-effects-and-anova" class="section level2" number="4.9">
<h2>
<span class="header-section-number">4.9</span> <strong>Paper Towels: The Relationship Between Effects and ANOVA</strong><a class="anchor" aria-label="anchor" href="#paper-towels-the-relationship-between-effects-and-anova"><i class="fas fa-link"></i></a>
</h2>
<p>Each of the three hypothesis tests in the paper towel study is tested on a separate line in an ANOVA table. The <span class="math inline">\(F\)</span>-statistics for an ANOVA were already calculated earlier in this chapter by comparing between group and within group variability. This section will show the relationship between calculating effects and the ANOVA table. For each null hypothesis, the statement “the means are equal for all levels of a factor” is equivalent to the statement “factor effects are zero.”</p>
<p>The <strong>sum of squares</strong> (SS) for a main factor in the multi-factor ANOVA is identical to the one-factor SS described in Chapter 2. The sum of squares (the numerator of the mean square calculation) is the sum of all squared effects corresponding to that factor. For the <em>Brand</em> effect, this is written mathematically as</p>
<p><span class="math display">\[\begin{align}
\text{SS}_{\text{Brand}} &amp;= \sum (\text{Brand effect on each of the 156 observations})^2 \notag \\
&amp;= \sum_{i=1}^{2} 78(\bar{y}_{i..} - \bar{y}_{...})^2
\notag
\end{align}\]</span></p>
<p>This equation can be generalized. Instead of 78 elements in each <em>Brand</em> group, we can indicate <span class="math inline">\(n_i\)</span> elements. Instead of 2 levels for <em>Brand</em>, we can indicate <span class="math inline">\(I\)</span> levels. The first factor, <em>Brand</em>, can be labeled factor <span class="math inline">\(A\)</span>; the second factor, <em>Water</em>, can be labeled factor <span class="math inline">\(B\)</span>; etc. Then</p>
<p><span class="math display">\[\begin{align}
\text{SS}_{\text{Brand}} = \text{SS}_A = \sum_{i=1}^{I} n_i(\bar{y}_{i..} - \bar{y}_{...})^2 \qquad \text{for} \quad I=2 \text{ (number of Brand levels)}
\tag{4.9}
\end{align}\]</span></p>
<p>Similarly, <span class="math inline">\(\text{SS}_{\text{Water}} = \text{SS}_B\)</span> is the sum of squares for the <em>Water</em> effect on each observation.</p>
<p><span class="math display">\[\begin{align}
\text{SS}_{\text{Water}} = \text{SS}_B = \sum (\text{Water effect on each of the 156 observations})^2 \notag \\
= \sum_{j=1}^{3} 52(\bar{y}_{.j.} - \bar{y}_{...})^2 \notag \\
= \sum_{j=1}^{J} n_j(\bar{y}_{.j.} - \bar{y}_{...})^2 \qquad \text{for} \quad J=3 \text{ (number of Water levels)}
\tag{4.10}
\end{align}\]</span></p>
<p>The sum of squares for the interaction term, <span class="math inline">\(\text{SS}_{AB}\)</span>, is</p>
<p><span class="math display">\[\begin{align}
\text{SS}_{AB} &amp;= \sum (\text{interaction effect on each of the 156 observations})^2 \notag \\
&amp;= \sum_{i=1}^{I} \sum_{j=1}^{J} n_{ij} (\text{ith level effect})^2 \notag \\
&amp;= \sum_{i=1}^{2} \sum_{j=1}^{3} 26 (\bar{y}_{ij.} - \bar{y}_{i..} - \bar{y}_{.j.} + \bar{y}_{...})^2
\tag{4.11}
\end{align}\]</span></p>
<p>The <strong>error sum of squares</strong> (<span class="math inline">\(\text{SS}_{\text{Error}}\)</span>) measures the spread of the observed residuals. Each residual is defined as an observed value minus the estimated value: <span class="math inline">\(\hat{\epsilon}_{ijk} = y_{ijk} - \bar{y}_{ij.}\)</span>.</p>
<p><span class="math display">\[\begin{align}
\text{SS}_{\text{Error}} &amp;= \sum (\text{each residual effect})^2 \notag \\
&amp;= \sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{n_{ij}} (y_{ijk} - \bar{y}_{ij.})^2 \notag \\
&amp;= \sum_{i=1}^{I} \sum_{j=1}^{J} \left[(n_{ij} - 1) \times s_{ij}^2 \right] \notag \\
&amp;= 25 \times s_{11}^2 + 25 \times s_{12}^2 + 25 \times s_{13}^2 + 25 \times s_{21}^2 + 25 \times s_{22}^2 + 25 \times s_{23}^2
\tag{4.12}
\end{align}\]</span></p>
<p>The <strong>total sum of squares</strong> (<span class="math inline">\(\text{SS}_{\text{Total}}\)</span>) measures the overall spread of the responses in the full data set.</p>
<p><span class="math display">\[\begin{align}
\text{SS}_{\text{Total}} &amp;= \sum (\text{distance between each observation and the grand mean})^2 \notag \\
&amp;= \sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{n_{ij}} (y_{ijk} - \bar{y}_{...})^2 \notag \\
&amp;= (N-1) \times s^2
\tag{4.13}
\end{align}\]</span></p>
<p><br>
The variance within each factor-level group is calculated as
<span class="math display">\[
s_{ij}^2 = \frac{\sum_{k=1}^{n_{ij}} (y_{ijk} - \bar{y}_{ij.})^2}{n_{ij} - 1}
\]</span>
and the overall sample variance of the response variable is
<span class="math display">\[
s^2 = \frac{\sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{n_{ij}} (y_{ijk} - \bar{y}_{...})^2}{N-1}
\]</span>
where <span class="math inline">\(N = 156\)</span> is the total sample size.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Degrees of Freedom {‑}</p>
<p><strong>Degrees of freedom</strong> (df) are determined by how many “free” pieces of information are available when calculating effects. For example, Equation (4.8) shows that each of the main effects must sum to zero. Thus, knowing the effects of any two levels of <em>water</em> forces a known effect for the last level. In our example, the effect of 0 drops of water increases the expected mean strength by 1264.4. Similarly, the effect of using 5 drops of water is -239.9. The the effects must sum to zero (<span class="math inline">\(\hat{\beta}_1 + \hat{\beta}_2 + \hat{\beta}_3 = 1264.4 - 239.9 - 1024.5 = 0\)</span>).</p>
<p><br>
For any main factor with <span class="math inline">\(J\)</span> levels, one effect is fixed if we know the other <span class="math inline">\(J-1\)</span> effects. Thus, when there are <span class="math inline">\(J\)</span> levels for a main factor of interest, there are <span class="math inline">\(J-1\)</span> degrees of freedom (free pieces of information).
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Extended Activity: Calculating Degrees of Freedom for Interaction Terms {‑}
&gt;Data set: <span class="math inline">\(PaperTowels\)</span><br>
31. Table 4.6 is a table with two rows and three columns, similar to the interaction effect term in the two-way factorial diagram in Figure 4.4. However, for this question we will assume that only two effects are known: <span class="math inline">\((\alpha\beta)_{11} = 2\)</span> and <span class="math inline">\((\alpha\beta)_{12} = -5\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Equation (4.8) states that all the <span class="math inline">\(AB\)</span> effects within Brand C add up to zero [<span class="math inline">\((\alpha\beta)_{11} + (\alpha\beta)_{12} + (\alpha\beta)_{13} = 0\)</span>]. Use this rule to calculate <span class="math inline">\((\alpha\beta)_{13}\)</span>.</p></li>
<li><p>Equation (4.8) also states that all the <span class="math inline">\(AB\)</span> effects within 0 water amount add up to zero (the same for 5 and 15 drops of water). Use this rule to calculate <span class="math inline">\((\alpha\beta)_{21}\)</span>, <span class="math inline">\((\alpha\beta)_{22}\)</span>, and <span class="math inline">\((\alpha\beta)_{23}\)</span>.</p></li>
<li><p>Consider a different interaction table with two rows and three columns. Explain why it is not possible to have effects of <span class="math inline">\((\alpha\beta)_{11} = 4\)</span>, <span class="math inline">\((\alpha\beta)_{13} = -4\)</span>, and <span class="math inline">\((\alpha\beta)_{22} = 6\)</span> and still follow the restrictions in Equation (4.8).</p></li>
<li><p>What are the degrees of freedom corresponding to any interaction term (in a balanced completely randomized design) with two levels of factor <span class="math inline">\(A\)</span> and three levels of factor <span class="math inline">\(B\)</span>? In other words, under the restrictions in Equation (4.8), what is the number of free pieces of information (the number of cells in Table 4.6 that are not fixed)?</p></li>
</ol>
<ol start="32" style="list-style-type: decimal">
<li>Table 4.7 is another table of interaction effects, with five rows and three columns (five levels of factor <span class="math inline">\(A\)</span> and three levels of factor <span class="math inline">\(B\)</span>). Again, we will assume that only some of the effects are known.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Use Equation (4.8) to calculate the effect corresponding to each of the remaining cells.</p></li>
<li><p>In Table 4.7, eight cells are filled. If only seven cells were filled, would it be possible to calculate the effects corresponding to all remaining cells?</p></li>
<li><p>What are the degrees of freedom corresponding to any interaction term (in a balanced completely randomized design) with five levels of factor <span class="math inline">\(A\)</span> and three levels of factor <span class="math inline">\(B\)</span>? In other words, what is the minimum number of cells that must be filled in order to allow us to use Equation (4.8) to estimate all other effects?</p></li>
</ol>
<ol start="33" style="list-style-type: decimal">
<li>Use the previous two questions to determine the degrees of freedom for an interaction term for a balanced completely randomized design using three levels of factor <span class="math inline">\(A\)</span> and four levels of factor <span class="math inline">\(B\)</span>.</li>
</ol>
<p>For the <span class="math inline">\(AB\)</span> interaction term, there are <span class="math inline">\(I \times J\)</span> effects that are calculated. In the popcorn study, <span class="math inline">\(I \times J = 2 \times 3 = 6\)</span>. Each effect represents one piece of information. In addition:</p>
<ul>
<li>All the <span class="math inline">\(AB\)</span> effects within Brand C add up to zero [<span class="math inline">\((\alpha\beta)_{11} + (\alpha\beta)_{12} + (\alpha\beta)_{13} = 0\)</span>]. Within Brand C, if two effects are known, the third will be fixed (the same holds for Brand D). Thus, these restrictions eliminate <span class="math inline">\(I = 2\)</span> free pieces of information (free cells in an interaction effects table).</li>
<li>Similarly, all the <span class="math inline">\(AB\)</span> effects within 0 water amount add up to zero [<span class="math inline">\((\alpha\beta)_{11} + (\alpha\beta)_{21} = 0\)</span>]. The same restriction holds for all other levels of factor <span class="math inline">\(B\)</span> (for 5 and 15 drops of water). Thus, an additional <span class="math inline">\(J = 3\)</span> pieces of information are no longer free. However, one piece of information is already fixed from the requirement that the sum of all brand effects is zero. Thus, only <span class="math inline">\(J-1 = 3-1=2\)</span> free pieces of information are taken for water amounts.</li>
</ul>
<p>The degrees of freedom for the interaction effect are
<span class="math display">\[\begin{align}
\text{df}_{AB} &amp;= \text{number of interaction effects} - [\text{df}_A + \text{df}_B + 1] \notag \\
&amp;= IJ - [(I-1) + (J-1) + 1] \notag \\
&amp;= IJ - I - J + 1 \notag \\
&amp;= (I-1)(J-1)
\tag{4.14}
\end{align}\]</span></p>
<p>
Calculating interaction degrees of freedom as <span class="math inline">\((I-1)(J-1)\)</span> in Equation (4.14) is quite easy. However, the reason Equation (4.14) also shows interaction df <span class="math inline">\(= IJ - [(I-1) + (J-1) + 1]\)</span> is that this follows the calculation of the interaction effect shown in Equation (4.7): <span class="math inline">\(\bar{y}_{ij.} - [(\bar{y}_{i.} - \bar{y}_{...}) + (\bar{y}_{.j.} - \bar{y}_{...}) + \bar{y}_{...}]\)</span>. The key point is to recognize that knowing how the effects are calculated drives formulas for both sum of squares and degrees of freedom. This is also true for more complex designs beyond the scope of this chapter.
</p>
<p><br>
For each term in a model, degrees of freedom represent the number of cells in a factor diagram that must be filled before all other cells can be filled with no added information. Thus, degrees of freedom are the number of “free” effects before the restrictions allow us to predict all other effects.
</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Extended Activity: Analyzing the Paper Towel Data{‑}
&gt;Data set: <span class="math inline">\(PaperTowels\)</span><br>
34. <strong>Checking Assumptions</strong> In the statistical model in Equation (4.5), the following assumptions need to be validated about the random error terms, <span class="math inline">\(\varepsilon_{ijk}\)</span>, before any formal hypothesis test can be developed:
- The error terms are independent and identically distributed.
- The error terms follow a normal probability distribution, denoted as <span class="math inline">\(\epsilon \sim N(0, \sigma^2)\)</span>.</p>
<p>Note that the second assumption includes an equal variance assumption about the random errors from the different factor-level groups: <span class="math inline">\(\sigma_{11}^2 = \sigma_{12}^2 = \sigma_{13}^2 = \sigma_{21}^2 = \sigma_{22}^2 = \sigma_{23}^2\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>The independence assumption implies that there is no relationship between one observation and the next. The identically distributed assumption means that each observation sampled within each brand/water combination is from a population with the same mean and variance. If all 26 paper towels were sampled from one roll to assess the Brand C/5 drops factor combination, would you be concerned about violating the independence and/or the identically distributed assumption? Why or why not?</p></li>
<li><p>Calculate the sample means and standard deviations of all six factor-level combinations. Clearly, some groups have much larger variation than others. In addition, the variation within each group increases as the average breaking strength increases. To address this issue, a transformation of the data can often be used that will “stabilize” the variances so that the equal variance assumption is reasonable on this new scale. (Chapter 2 describes transformations in more detail.)</p></li>
<li><p>Transform the response variable using natural log (<span class="math inline">\(\log(\text{Strength})\)</span>) and <span class="math inline">\(\sqrt{\text{Strength}}\)</span>. Did both transformations improve the equal variance assumption?</p></li>
</ol>
<ol start="35" style="list-style-type: decimal">
<li>
<strong>Visualizing the Data</strong> Draw individual value plots or side-by-side boxplots of the square-root transformed responses in the six factor-level groups.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Is there any extreme skewness or outliers that would cause us to question the normality assumption?</li>
<li>Without doing any statistical calculations, do you expect to reject the three null hypotheses for the paper towel study? Justify your answer by visually comparing the variation (i.e., the spread) in the strength between groups to the variation within groups.</li>
</ol>
<ol start="36" style="list-style-type: decimal">
<li>
<strong>Analyzing the Data</strong> Use computer software to conduct an analysis on the square-root transformed <span class="math inline">\(PaperTowels\)</span> data to test for differences between brands, water levels, and interactions. Use the ANOVA as well as appropriate graphs to state your conclusions about the paper towel study.</li>
</ol>
</div>
<div id="contrasts-and-multiple-comparisons" class="section level2" number="4.10">
<h2>
<span class="header-section-number">4.10</span> <strong>Contrasts and Multiple Comparisons</strong><a class="anchor" aria-label="anchor" href="#contrasts-and-multiple-comparisons"><i class="fas fa-link"></i></a>
</h2>
<p>Chapter 2 describes a study where researchers tested whether a color distracter influenced the completion time of an online computer game. In addition to a color distracter, they were also interested in whether subjects could play the game more quickly with their right or left hand. Chapter 2 was restricted to one-factor ANOVAs. Thus, in that chapter the data were sorted into four groups: StandardRight, ColorRight, StandardLeft, and ColorLeft. Instead of testing for evidence against a general hypothesis test (<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{SR} = \mu_{CR} = \mu_{SL} = \mu_{CL}\)</span>), the two-way ANOVA allows us to test three more specific hypotheses of interest.</p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Extended Activity:<em>Comparing One-Way and Two-Way ANOVA</em>{‑}
&gt;Data set: <em>Games2</em>
37. The data set <strong>Games2</strong> shows a column <em>Type2</em> with four types of games based on distracter and which hand was used. Conduct an ANOVA using <em>Type2</em> (just one explanatory variable with four levels) to test for differences in completion time. What is the <span class="math inline">\(p\)</span>-value corresponding to the null hypothesis <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{SR} = \mu_{CR} = \mu_{SL} = \mu_{CL}\)</span> versus the alternative <span class="math inline">\(H_a\)</span>: at least one mean is different from another?<br>
38. Conduct a two-way ANOVA using <em>Type</em>, <em>Hand</em>, and the <em>Type</em> <span class="math inline">\(\ast\)</span> <em>Hand</em> interaction to test for differences in completion time. List the three null and alternative hypotheses and provide a <span class="math inline">\(p\)</span>-value for each test.<br>
39. Since the same response variable is used for both Question 37 and Question 38, it should not be surprising that the total sum of squares is identical for both questions. Compare the other sums of squares in the ANOVAs from Questions 37 and 38. How is <span class="math inline">\(SS_{\text{Type2}}\)</span> related to <span class="math inline">\(SS_{\text{Type}}\)</span>, <span class="math inline">\(SS_{\text{Hand}}\)</span>, and <span class="math inline">\(SS_{\text{TypeHand}}\)</span>?</p>
<p>Since Question 37 leads us to reject <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{SR} = \mu_{CR} = \mu_{SL} = \mu_{CL}\)</span>, it seems reasonable to conduct a multiple comparisons test (conduct multiple tests to identify differences between each group mean and every other group mean).</p>
<p><br>
There are six possible comparisons when there are four group means. Chapter 1 discussed familywise type I error and comparisonwise type I error. The <strong>least-significant differences method</strong> is a technique using comparisonwise type I error: If the <span class="math inline">\(p\)</span>-value is less than <span class="math inline">\(\alpha\)</span>, reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_a\)</span>. Assuming that a particular null hypothesis is true, the least-significant differences method has an <span class="math inline">\(\alpha\%\)</span> chance of (incorrectly) rejecting that hypothesis. When multiple tests are conducted on the same data set, the least-significant differences method leads to type I errors: rejecting null hypotheses when they should not be rejected.</p>
<p><strong>Bonferroni’s method</strong> is an example of a technique that maintains familywise type I error: If the <span class="math inline">\(p\)</span>-value is less than <span class="math inline">\(\alpha/K\)</span> (where <span class="math inline">\(K\)</span> is the number of pairs), reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_a\)</span>. With the familywise type I error = <span class="math inline">\(\alpha\)</span>, assuming that there really is no difference between any of the <span class="math inline">\(K\)</span> pairs, there is only an <span class="math inline">\(\alpha\%\)</span> chance that any test will reject <span class="math inline">\(H_0\)</span>. This leads to type II errors: failing to reject null hypotheses when they should be rejected. Chapter 1 describes the need for multiple comparison procedures and describes both the least-significant difference and the Bonferroni method in more detail.
</p>
<p>Question 38 can be thought of as testing for orthogonal contrasts. An <strong>orthogonal contrast</strong> is a linear combination of treatment means where the coefficients add up to zero. For example, before they collected any data, the researchers in the game study were interested in several specific comparisons:</p>
<ul>
<li>Comparing standard to color games: <span class="math inline">\(H_{01}\)</span>: (1)<span class="math inline">\(\mu_{SR}\)</span> + (-1)<span class="math inline">\(\mu_{CR}\)</span> + (1)<span class="math inline">\(\mu_{SL}\)</span> + (-1)<span class="math inline">\(\mu_{CL}\)</span> = 0. This is mathematically equivalent to <span class="math inline">\(H_{01}\)</span>: <span class="math inline">\((\frac{1}{2})\mu_{SR} + (\frac{1}{2})\mu_{SL} = (\frac{1}{2})\mu_{CR} + (\frac{1}{2})\mu_{CL}\)</span> or <span class="math inline">\(H_{01}\)</span>: <span class="math inline">\(\mu_{S} = \mu_{C}\)</span>.</li>
<li>Comparing right to left hand: <span class="math inline">\(H_{02}\)</span>: (1)<span class="math inline">\(\mu_{SR}\)</span> + (1)<span class="math inline">\(\mu_{CR}\)</span> + (-1)<span class="math inline">\(\mu_{SL}\)</span> + (-1)<span class="math inline">\(\mu_{CL}\)</span> = 0. This is mathematically equivalent to <span class="math inline">\(H_{02}\)</span>: <span class="math inline">\(\mu_{R} = \mu_{L}\)</span>.</li>
<li>Testing for an interaction: <span class="math inline">\(H_{03}\)</span>: (1)<span class="math inline">\(\mu_{SR}\)</span> + (-1)<span class="math inline">\(\mu_{CR}\)</span> + (-1)<span class="math inline">\(\mu_{SL}\)</span> + (1)<span class="math inline">\(\mu_{CL}\)</span> = 0.</li>
</ul>
<p>Each of these linear combinations of population means can be estimated by a contrast:</p>
<p><span class="math display">\[\begin{align}
\text{Contrast 1 (C1)} &amp;= (1)\bar{y}_{SR} + (-1)\bar{y}_{CR} + (1)\bar{y}_{SL} + (-1)\bar{y}_{CL} \notag \\
\text{Contrast 2 (C2)} &amp;= (1)\bar{y}_{SR} + (1)\bar{y}_{CR} + (-1)\bar{y}_{SL} + (-1)\bar{y}_{CL} \notag \\
\text{Contrast 3 (C3)} &amp;= (1)\bar{y}_{SR} + (-1)\bar{y}_{CR} + (-1)\bar{y}_{SL} + (1)\bar{y}_{CL}
\notag
\end{align}\]</span></p>
<p>The coefficients of each of the linear combinations sum to zero:</p>
<p><span class="math display">\[\begin{align}
\text{Coefficients for contrast 1} &amp;= C_{11} + C_{21} + C_{31} + C_{41} = (1) + (-1) + (1) + (-1) = 0 \notag \\
\text{Coefficients for contrast 2} &amp;= C_{12} + C_{22} + C_{32} + C_{42} = (1) + (1) + (-1) + (-1) = 0 \notag \\
\text{Coefficients for contrast 3} &amp;= C_{13} + C_{23} + C_{33} + C_{43} = (1) + (-1) + (-1) + (1) = 0
\notag
\end{align}\]</span></p>
<p><br>
For any null hypothesis test comparing <span class="math inline">\(G\)</span> group means <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_1 = \mu_2 = \cdots = \mu_G\)</span> versus the alternative <span class="math inline">\(H_a\)</span>: at least one group mean is different from another, a contrast is an estimate of a linear combination of the group means: Contrast 1 (<span class="math inline">\(C_1\)</span>) = (<span class="math inline">\(C_{11}\)</span>)<span class="math inline">\(\bar{y}_1\)</span> + (<span class="math inline">\(C_{21}\)</span>)<span class="math inline">\(\bar{y}_2\)</span> + <span class="math inline">\(\cdots\)</span> + (<span class="math inline">\(C_{G1}\)</span>)<span class="math inline">\(\bar{y}_G\)</span>, where the coefficients sum to zero: <span class="math inline">\(C_{11} + C_{21} + \cdots + C_{G1} = 0\)</span>.
</p>
<p><br>
Any set of <span class="math inline">\(G\)</span> group means (four group means in our case; <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{SR} = \mu_{CR} = \mu_{SL} = \mu_{CL}\)</span>) being compared in a between group sum of squares can be used to create <span class="math inline">\(G-1\)</span> mutually orthogonal contrasts (<span class="math inline">\(H_{01}, H_{02}, H_{03}\)</span>). Any two contrasts are said to be orthogonal if the dot product (sum of the cross products) of their coefficient vectors is zero. Contrasts must be orthogonal to ensure that they are independent. This independence allows us to partition the variation in ANOVA, so that the sum of squares corresponding to all <span class="math inline">\(G-1\)</span> contrasts will sum to the between group sum of squares.
</p>
<p>Often contrasts are incorporated into the ANOVA analysis. The <span class="math inline">\(F\)</span>-statistic for a contrast is simply the mean square for a particular between groups measure (for example, <span class="math inline">\(MS_{C1}\)</span> is the mean square for <span class="math inline">\(C_1\)</span>) divided by the pooled within group variances (MSE). We can write the mean square for a contrast as</p>
<p><span class="math display">\[\begin{align}
MS_{C1} = \frac{(C1)^2}{\sum_{g=1}^{G} \frac{C_{g1}^2}{n_g}}
\tag{4.15}
\end{align}\]</span></p>
<p>where <span class="math inline">\(C_{g1}\)</span> is the contrast coefficient and <span class="math inline">\(n_g\)</span> is the sample size for each group. In the game study,</p>
<p><span class="math display">\[\begin{align}
C1 &amp;= (1)\bar{y}_{SR} + (-1)\bar{y}_{CR} + (1)\bar{y}_{SL} + (-1)\bar{y}_{CL} \notag \\
   &amp;= (1)34 + (-1)36 + (1)37.1 + (-1)40.2 \notag \\
   &amp;= -5.1 \notag
\end{align}\]</span></p>
<p>Thus, the mean square for contrast 1 (<span class="math inline">\(MS_{C1}\)</span>) based on Question 37 is identical to the mean square for game type (<span class="math inline">\(MS_{\text{Type}}\)</span>) in Question 38:</p>
<p><span class="math display">\[\begin{align}
MS_{C1} &amp;= \frac{1^2}{10} + \frac{(-1)^2}{10} + \frac{1^2}{10} + \frac{(-1)^2}{10} \notag \\
        &amp;= \frac{(-5.1)^2}{0.4} \notag \\
        &amp;= 65.025 = MS_{\text{Type}} \notag
\end{align}\]</span></p>
<p>[[[ This part not working. The heading is numbered, but it shouldnt be.
## Extended Activity: Calculating Contrasts{‑}
&gt;Data set: <em>Games2</em><br>
40. Use Equation (4.15) to calculate <span class="math inline">\(MS_{C2}\)</span> and <span class="math inline">\(MS_{C3}\)</span>. Show your work.<br>
41. Compare <span class="math inline">\(MS_{C2}\)</span> and <span class="math inline">\(MS_{C3}\)</span>, the mean squares found in Question 38.</p>
<p><br>
Orthogonal contrasts allow multiple comparisons of linear combinations of group means. The key advantage of contrasts is that they do not have inflated type I or type II errors. However, contrasts should always be determined <em>before</em> any data are collected. Looking at the data in order to develop contrasts will bias your results.
</p>
<p><br>
There are a few other common techniques for multiple comparisons. <strong>Scheffé’s method</strong> produces simultaneous confidence intervals for any and all contrasts, including contrasts suggested by the data (this is often called post hoc data exploration). Instead of the traditional formula for confidence intervals, Scheffé suggested using a wider confidence interval (i.e., one less likely to reject the null hypothesis) to account for the multiple testing. This method often fails to reject null hypotheses even when there are differences between groups, but it can be useful when other pairwise comparison tests are not appropriate. Remember from your introductory statistics course: If zero is in the confidence interval, you fail to reject the corresponding hypothesis test; if zero is not in the confidence interval, you should reject the corresponding hypothesis test. <strong>Tukey’s honest significant difference (HSD)</strong> uses a studentized range distribution instead of the F-distribution to create confidence intervals for differences between meaningful pairs. When there are a large number of pairwise comparisons, Tukey’s method is typically preferred over Bonferroni’s method.<span class="math inline">\(^6\)</span>
</p>
</div>
<div id="chapter-summary-3" class="section level2 unnumbered">
<h2>
<strong>Chapter Summary</strong><a class="anchor" aria-label="anchor" href="#chapter-summary-3"><i class="fas fa-link"></i></a>
</h2>
<p>This chapter emphasized the importance of a well-designed experiment. A statistician often needs to communicate with people in other fields in order to properly define the research question, choose appropriate factors and levels, and determine the number of samples needed for the study.</p>
<p>A <span class="math inline">\(p\)</span>-value never tells the whole story; <span class="math inline">\(p\)</span>-values can be meaningless if assumptions are not met or if there are extraneous variables in the data. Before any conclusions are drawn from a statistical analysis using ANOVA, it is important to use graphs or formal tests to validate the the equal variance and normality assumptions.</p>
<p>When equal variance or normality assumptions are violated, the <span class="math inline">\(F\)</span>-statistics do not follow an <span class="math inline">\(F\)</span>-distribution and the <span class="math inline">\(p\)</span>-values may not be accurate. Empirical studies have shown that ANOVA tends to be fairly “robust” to departures from the assumptions of equal variances and normality. If the model assumptions are not met, researchers should try transforming the data to better fit the model assumptions. If no transformation appears to help, researchers should clearly explain that the <span class="math inline">\(p\)</span>-values may not be reliable.</p>
The independence and identically distributed assumptions are also essential. A good experimental design has the following characteristics:
<p>ANOVA tables are used to test for differences in means among meaningful groups of data. The analysis is called an analysis of variance because each mean square value is an estimate of a meaningful group within the data. The extended activities demonstrated how to calculate an ANOVA table; they emphasized main effects and interaction effects. An interaction between two variables occurs when the effect of one variable depends on the second variable. While this chapter emphasized a two-factor ANOVA, the same process holds for all completely randomized designs with fixed factors.</p>
<p>This chapter introduced the basics of a very powerful statistical technique. The ability to simultaneously test for the effects of multiple variables on a response allows statisticians to better model real-world situations. A well-designed experiment can test multiple hypotheses with a relatively small sample size. If used properly, these techniques efficiently and reliably help us better understand the world we live in. The end-of-chapter exercises and future chapters provide the opportunity for you to experience for yourself how these techniques are used in biology, chemistry, engineering, psychology, and many other disciplines.</p>
[[[ This part not working. All the text under the heading is not showing up
## <strong>Exercises</strong>{-}

<p>[[[ This part not working. All the text under the heading is not showing up
## <strong>Endnotes</strong>{-}</p>

</div>
</div>

  <div class="chapter-nav">
<div class="empty"></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Book Chapter Example</strong>" was written by Your Name. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
